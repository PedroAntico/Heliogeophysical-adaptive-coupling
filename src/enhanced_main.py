#!/usr/bin/env python3
"""
Pipeline Principal Aprimorado - Heliogeophysical Adaptive Coupling v3.0
Inclui ML Preditivo, M√∫ltiplas Fontes de Dados e Detec√ß√£o Avan√ßada
"""
import logging
import yaml
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

# Importa√ß√µes internas
from src.utils.logger import setup_logging
from src.fetchers.noaa_fetcher import create_noaa_fetcher
from src.fetchers.nasa_cdaweb_fetcher import create_nasa_fetcher
from src.fetchers.ensemble_fetcher import create_ensemble_fetcher
from src.processing.preprocessor import DataPreprocessor
from src.detection.advanced_detector import create_advanced_detector
from src.model.predictive_model import create_predictor

class EnhancedHeliogeophysicalPipeline:
    """Pipeline aprimorado com ML e m√∫ltiplas fontes"""
    
    def __init__(self, config_path: str = "src/config/config.yaml"):
        self.config_path = config_path
        self.config = self._load_config()
        self.logger = setup_logging(
            self.config['logging']['file'],
            self.config['logging']['level']
        )
        
        # Inicializa componentes avan√ßados
        self.noaa_fetcher = create_noaa_fetcher(self.config['data_sources']['noaa'])
        self.nasa_fetcher = create_nasa_fetcher(self.config['data_sources'].get('nasa_cdaweb', {}))
        self.ensemble_fetcher = create_ensemble_fetcher(self.noaa_fetcher, self.nasa_fetcher)
        self.preprocessor = DataPreprocessor(
            self.config['processing']['resample_frequency']
        )
        self.advanced_detector = create_advanced_detector(self.config['detection'])
        self.predictor = create_predictor()
    
    def _load_config(self) -> dict:
        """Carrega configura√ß√£o do arquivo YAML"""
        try:
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"Erro ao carregar configura√ß√£o: {e}")
            return {}
    
    def run_enhanced_pipeline(self) -> dict:
        """Executa pipeline aprimorado completo"""
        self.logger.info("üöÄ Iniciando pipeline HELIOGEOPHYSICAL 3.0")
        
        try:
            # Fase 1: Coleta de Dados com Ensemble
            self.logger.info("üì° Coletando dados de m√∫ltiplas fontes...")
            ensemble_data = self._fetch_ensemble_data()
            
            if ensemble_data.empty:
                self.logger.warning("Nenhum dado coletado do ensemble")
                return {"events": [], "status": "no_data"}
            
            # Fase 2: Processamento Avan√ßado
            self.logger.info("‚öôÔ∏è Processamento avan√ßado de dados...")
            processed_data = self._advanced_processing(ensemble_data)
            
            # Fase 3: Detec√ß√£o de Eventos (Modo B√°sico)
            self.logger.info("üîç Detec√ß√£o b√°sica de eventos...")
            basic_events = self._basic_event_detection(processed_data)
            
            # Fase 4: Treinamento/Atualiza√ß√£o do Modelo Preditivo
            self.logger.info("üß† Opera√ß√µes de Machine Learning...")
            ml_results = self._ml_operations(processed_data, basic_events)
            
            # Fase 5: Detec√ß√£o Avan√ßada com ML
            self.logger.info("üéØ Detec√ß√£o avan√ßada com ML...")
            final_events = self._advanced_event_detection(processed_data, ml_results.get('predictions'))
            
            # Fase 6: An√°lise e Relat√≥rios
            self.logger.info("üìä Gerando relat√≥rios avan√ßados...")
            analysis_report = self._generate_analysis_report(
                processed_data, final_events, ml_results
            )
            
            # Fase 7: Persist√™ncia de Resultados
            self._save_enhanced_results(processed_data, final_events, ml_results, analysis_report)
            
            self.logger.info(f"‚úÖ Pipeline conclu√≠do ‚Äî {len(final_events)} eventos detectados")
            
            return {
                "events": final_events,
                "ml_results": ml_results,
                "analysis": analysis_report,
                "processed_records": len(processed_data),
                "status": "success",
                "pipeline_version": "3.0",
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro no pipeline: {e}")
            return {
                "events": [],
                "status": "error",
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }
    
    def _fetch_ensemble_data(self) -> pd.DataFrame:
        """Coleta dados usando estrat√©gia de ensemble"""
        return self.ensemble_fetcher.fetch_ensemble_data(days=3)
    
    def _advanced_processing(self, data: pd.DataFrame) -> pd.DataFrame:
        """Processamento avan√ßado com features para ML"""
        processed = self.preprocessor.preprocess_data([data])
        
        if processed is not None:
            # Adiciona features espec√≠ficas para ML
            processed = self.predictor.prepare_features(processed)
        
        return processed if processed is not None else pd.DataFrame()
    
    def _basic_event_detection(self, data: pd.DataFrame) -> list:
        """Detec√ß√£o b√°sica de eventos para treinamento do ML"""
        from src.detection.simple_detector import detect_events
        return detect_events(data)
    
    def _ml_operations(self, data: pd.DataFrame, events: list) -> dict:
        """Opera√ß√µes de Machine Learning"""
        ml_results = {
            "training_status": "skipped",
            "prediction_status": "skipped",
            "predictions": pd.DataFrame()
        }
        
        try:
            # Verifica se h√° dados suficientes para treinamento
            if len(data) >= 100 and len(events) >= 5:
                self.logger.info("üîÑ Treinando/Atualizando modelo preditivo...")
                
                # Treina o modelo
                training_result = self.predictor.train(data, events)
                ml_results["training_status"] = training_result.get("status", "unknown")
                ml_results["training_metrics"] = training_result
                
                if training_result.get("status") == "success":
                    self.logger.info(f"‚úÖ Modelo treinado - Acur√°cia: {training_result.get('accuracy', 0):.3f}")
            
            # Faz previs√µes com o modelo
            self.logger.info("üîÆ Fazendo previs√µes com ML...")
            predictions, probabilities = self.predictor.predict(data)
            
            if not predictions.empty:
                ml_results["prediction_status"] = "success"
                ml_results["predictions"] = predictions
                ml_results["prediction_confidence"] = probabilities.tolist()
                self.logger.info(f"üìà Previs√µes ML: {predictions['predicted_event'].sum()} eventos previstos")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro nas opera√ß√µes de ML: {e}")
            ml_results["error"] = str(e)
        
        return ml_results
    
    def _advanced_event_detection(self, data: pd.DataFrame, ml_predictions: pd.DataFrame) -> list:
        """Detec√ß√£o avan√ßada integrando ML"""
        return self.advanced_detector.detect_advanced_events(data, ml_predictions)
    
    def _generate_analysis_report(self, data: pd.DataFrame, events: list, ml_results: dict) -> dict:
        """Gera relat√≥rio anal√≠tico avan√ßado"""
        
        report = {
            "timestamp": datetime.utcnow().isoformat(),
            "data_quality": {
                "total_records": len(data),
                "data_completeness": data.notna().mean().mean(),
                "temporal_coverage_hours": self._calculate_temporal_coverage(data),
                "variables_available": list(data.select_dtypes(include=[np.number]).columns)
            },
            "events_summary": {
                "total_events": len(events),
                "by_type": self._count_events_by_type(events),
                "by_severity": self._count_events_by_severity(events),
                "by_detection_method": self._count_events_by_method(events)
            },
            "ml_insights": {
                "model_trained": ml_results.get("training_status") == "success",
                "predictions_made": ml_results.get("prediction_status") == "success",
                "predicted_events": int(ml_results.get("predictions", pd.DataFrame()).get("predicted_event", pd.Series()).sum()),
                "average_confidence": np.mean(ml_results.get("prediction_confidence", [])) if ml_results.get("prediction_confidence") else 0
            },
            "recommendations": self._generate_recommendations(events, ml_results)
        }
        
        return report
    
    def _calculate_temporal_coverage(self, data: pd.DataFrame) -> float:
        """Calcula cobertura temporal em horas"""
        if len(data) < 2:
            return 0
        time_span = data['timestamp'].max() - data['timestamp'].min()
        return time_span.total_seconds() / 3600
    
    def _count_events_by_type(self, events: list) -> dict:
        """Conta eventos por tipo"""
        from collections import Counter
        return dict(Counter(event['type'] for event in events))
    
    def _count_events_by_severity(self, events: list) -> dict:
        """Conta eventos por severidade"""
        from collections import Counter
        return dict(Counter(event['severity'] for event in events))
    
    def _count_events_by_method(self, events: list) -> dict:
        """Conta eventos por m√©todo de detec√ß√£o"""
        from collections import Counter
        return dict(Counter(event.get('detection_method', 'unknown') for event in events))
    
    def _generate_recommendations(self, events: list, ml_results: dict) -> list:
        """Gera recomenda√ß√µes baseadas na an√°lise"""
        recommendations = []
        
        # Recomenda√ß√µes baseadas em eventos
        critical_events = [e for e in events if e.get('severity') in ['high', 'critical']]
        if critical_events:
            recommendations.append("‚ö†Ô∏è Eventos cr√≠ticos detectados - Monitoramento intensivo recomendado")
        
        # Recomenda√ß√µes baseadas em ML
        if ml_results.get("training_status") == "success":
            accuracy = ml_results.get("training_metrics", {}).get("accuracy", 0)
            if accuracy < 0.7:
                recommendations.append("ü§ñ Modelo ML com acur√°cia baixa - Considere retreinamento com mais dados")
        
        if not recommendations:
            recommendations.append("‚úÖ Situa√ß√£o normal - Continue monitoramento de rotina")
        
        return recommendations
    
    def _save_enhanced_results(self, data: pd.DataFrame, events: list, ml_results: dict, analysis: dict):
        """Salva resultados aprimorados"""
        timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        
        # Salva dados processados
        data_path = f"data/processed/helio_enhanced_{timestamp}.csv"
        data.to_csv(data_path, index=False)
        
        # Salva eventos
        if events:
            events_path = f"data/processed/events_enhanced_{timestamp}.json"
            with open(events_path, 'w') as f:
                json.dump(events, f, indent=2, default=str)
        
        # Salva resultados ML
        if not ml_results.get("predictions", pd.DataFrame()).empty:
            ml_path = f"data/processed/ml_predictions_{timestamp}.csv"
            ml_results["predictions"].to_csv(ml_path, index=False)
        
        # Salva relat√≥rio de an√°lise
        report_path = f"data/processed/analysis_report_{timestamp}.json"
        with open(report_path, 'w') as f:
            json.dump(analysis, f, indent=2, default=str)
        
        self.logger.info(f"üíæ Resultados salvos com prefixo: {timestamp}")

def main():
    """Fun√ß√£o principal"""
    pipeline = EnhancedHeliogeophysicalPipeline()
    result = pipeline.run_enhanced_pipeline()
    
    # Relat√≥rio Executivo Expandido
    print(f"\n{'='*60}")
    print("üåå RELAT√ìRIO EXECUTIVO - HELIOGEOPHYSICAL 3.0")
    print(f"{'='*60}")
    print(f"üìÖ Timestamp: {result['timestamp']}")
    print(f"üîÑ Status: {result['status']}")
    print(f"üìä Registros processados: {result.get('processed_records', 0)}")
    print(f"üö® Eventos detectados: {len(result['events'])}")
    print(f"ü§ñ Status ML: {result.get('ml_results', {}).get('training_status', 'N/A')}")
    
    # An√°lise de Eventos
    if result['events']:
        print(f"\nüìà AN√ÅLISE DE EVENTOS:")
        events_by_type = result.get('analysis', {}).get('events_summary', {}).get('by_type', {})
        for event_type, count in events_by_type.items():
            print(f"   ‚Ä¢ {event_type}: {count} eventos")
    
    # Recomenda√ß√µes
    recommendations = result.get('analysis', {}).get('recommendations', [])
    if recommendations:
        print(f"\nüí° RECOMENDA√á√ïES:")
        for rec in recommendations:
            print(f"   ‚Ä¢ {rec}")
    
    print(f"{'='*60}")
    print("üéØ Sistema heliogeof√≠sico avan√ßado operacional!")

if __name__ == "__main__":
    main()
