"""
heliopredictive.py ‚Äî Forecast experimental baseado na Teoria HAC (Pedro Antico, 2025)

M√≥dulo aprimorado com:
- M√∫ltiplos horizontes de previs√£o (1‚Äì12h)
- Ensemble (Ridge + RandomForest + XGBoost + ElasticNet)
- Feature engineering temporal baseado na Teoria HAC
- Valida√ß√£o cruzada temporal robusta
- Compara√ß√£o com benchmark de persist√™ncia
- Visualiza√ß√£o autom√°tica de resultados
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit
import xgboost as xgb
import warnings
warnings.filterwarnings("ignore")


# ================================================================
# üí° Classe principal de previs√£o HAC
# ================================================================
class HACForecaster:
    def __init__(self):
        self.models = {}
        self.results = {}
        self.feature_importance = {}

    # ============================================================
    # Cria√ß√£o de features temporais baseadas na teoria HAC
    # ============================================================
    def create_temporal_features(self, df, max_lag=6):
        df = df.copy()
        base_features = ["Delta_alpha", "Tau_fb", "Sigma_R", "Bz", "Dst"]

        # Lags
        for f in base_features:
            for lag in range(1, max_lag + 1):
                df[f"{f}_lag{lag}"] = df[f].shift(lag)

        # Tend√™ncia e volatilidade
        df["Bz_rolling_mean_3h"] = df["Bz"].rolling(3).mean()
        df["Bz_rolling_std_3h"] = df["Bz"].rolling(3).std()
        df["Dst_rolling_mean_3h"] = df["Dst"].rolling(3).mean()
        df["Dst_trend"] = df["Dst"].diff(3)

        # Intera√ß√µes
        df["Bz_Dst_interaction"] = df["Bz"] * df["Dst_rolling_mean_3h"]
        df["Complexity_Index"] = df["Delta_alpha"] * df["Sigma_R"]

        # Condi√ß√µes de regime
        df["storm_condition"] = (df["Dst"] < -30).astype(int)
        df["Bz_negative"] = (df["Bz"] < 0).astype(int)

        return df.dropna()

    # ============================================================
    # Prepara features e target (prevendo Dst futuro)
    # ============================================================
    def prepare_features_targets(self, df, horizon=6, test_size=0.2):
        df_feat = self.create_temporal_features(df)
        df_feat["Dst_target"] = df_feat["Dst"].shift(-horizon)
        df_feat = df_feat.dropna()

        feature_columns = [
            c for c in df_feat.columns
            if c not in ["Dst", "Dst_target", "Time_h"] and not c.startswith("Dst_lag")
        ]

        X = df_feat[feature_columns].values
        y = df_feat["Dst_target"].values

        split_idx = int(len(X) * (1 - test_size))
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]

        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        return X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_columns

    # ============================================================
    # Ensemble de modelos
    # ============================================================
    def train_ensemble(self, X_train, y_train, X_test, y_test, horizon):
        models = {
            "Ridge": Ridge(alpha=1.0, random_state=42),
            "RandomForest": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),
            "XGBoost": xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42),
            "ElasticNet": ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42),
        }

        predictions = {}
        scores = {}

        for name, model in models.items():
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            rmse = mean_squared_error(y_test, y_pred, squared=False)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            predictions[name] = y_pred
            scores[name] = {"RMSE": rmse, "MAE": mae, "R2": r2}
            print(f"  {name:12} | RMSE: {rmse:6.2f} | MAE: {mae:6.2f} | R¬≤: {r2:6.3f}")

        # Ensemble (m√©dia)
        ensemble_pred = np.mean(list(predictions.values()), axis=0)
        ensemble_rmse = mean_squared_error(y_test, ensemble_pred, squared=False)
        ensemble_r2 = r2_score(y_test, ensemble_pred)
        scores["Ensemble"] = {"RMSE": ensemble_rmse, "MAE": np.mean([s["MAE"] for s in scores.values()]), "R2": ensemble_r2}
        print(f"  {'Ensemble':12} | RMSE: {ensemble_rmse:6.2f} | R¬≤: {ensemble_r2:6.3f}")

        return models, scores, ensemble_pred

    # ============================================================
    # Benchmark: modelo persistente (√∫ltimo valor)
    # ============================================================
    def persistence_benchmark(self, y_test):
        """
        Calcula o modelo de persist√™ncia (baseline) e seus erros.
        """
        import numpy as np
        from sklearn.metrics import mean_squared_error, r2_score

        # Cria previs√£o de persist√™ncia (valor anterior como pr√≥ximo)
        y_persist = np.roll(y_test, 1)
        y_persist[0] = np.mean(y_test)

        # Calcula erros
        mse = mean_squared_error(y_test, y_persist)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_test, y_persist)

        return {"RMSE": rmse, "R2": r2}, y_persist

    # ============================================================
    # Previs√£o principal
    # ============================================================
    def forecast(self, df, horizon=6):
        print(f"\nüéØ Previs√£o HAC ‚Äî Horizonte {horizon}h")
        X_train, X_test, y_train, y_test, scaler, feature_columns = self.prepare_features_targets(df, horizon=horizon)

        persist_scores, y_persist = self.persistence_benchmark(y_test)
        print(f"\nüìä Persist√™ncia | RMSE: {persist_scores['RMSE']:.2f} | R¬≤: {persist_scores['R2']:.3f}")

        models, scores, y_ensemble = self.train_ensemble(X_train, y_train, X_test, y_test, horizon)
        improvement = 1 - (scores["Ensemble"]["RMSE"] / persist_scores["RMSE"])
        print(f"üìà Melhoria vs persist√™ncia: {improvement:.1%}")

        self.results[horizon] = {
            "y_test": y_test,
            "y_pred": y_ensemble,
            "scores": scores,
            "improvement": improvement,
            "persist": persist_scores,
        }
        return self.results[horizon]

    # ============================================================
    # Visualiza√ß√£o
    # ============================================================
    def plot_results(self, horizon=6):
        r = self.results[horizon]
        plt.figure(figsize=(12, 6))
        plt.plot(r["y_test"], label="Observado", lw=2)
        plt.plot(r["y_pred"], label="Ensemble", alpha=0.8)
        plt.title(f"Previs√£o HAC - Horizonte {horizon}h")
        plt.legend()
        plt.grid(alpha=0.3)
        os.makedirs("results", exist_ok=True)
        path = f"results/hac_forecast_h{horizon}.png"
        plt.savefig(path, dpi=300, bbox_inches="tight")
        plt.close()
        print(f"üíæ Gr√°fico salvo em {path}")


# ================================================================
# üî≠ Gerador de dados simulados (fallback)
# ================================================================
def generate_realistic_data(n_points=500):
    np.random.seed(42)
    t = np.linspace(0, 20, n_points)
    storm = -80 * np.exp(-(t - 10) ** 2 / 2) + np.random.normal(0, 8, n_points)
    Dst = storm
    Bz = -10 * np.exp(-(t - 10) ** 2 / 3) + np.random.normal(0, 2, n_points)
    Delta_alpha = 0.5 + 0.2 * np.sin(2 * np.pi * t / 6)
    Tau_fb = 6 + np.sin(2 * np.pi * t / 8)
    Sigma_R = 4 + 0.5 * np.sin(2 * np.pi * t / 9)
    return pd.DataFrame({"Time_h": np.arange(n_points),
                         "Delta_alpha": Delta_alpha,
                         "Tau_fb": Tau_fb,
                         "Sigma_R": Sigma_R,
                         "Bz": Bz,
                         "Dst": Dst})


# ================================================================
# üöÄ Execu√ß√£o principal
# ================================================================
def main():
    print("üöÄ Sistema HAC Forecast iniciado")

    # Tenta usar dados reais, sen√£o gera sint√©ticos
    data_path = "data/solar_data_latest.csv"
    if os.path.exists(data_path):
        print("üõ∞Ô∏è Carregando dados reais...")
        df_raw = pd.read_csv(data_path)
        df_raw = df_raw.rename(columns={"speed": "Bz", "density": "Dst"})
        df_raw["Delta_alpha"] = np.abs(np.sin(np.arange(len(df_raw)) / 10)) + 0.2
        df_raw["Tau_fb"] = 6 + np.cos(np.arange(len(df_raw)) / 8)
        df_raw["Sigma_R"] = 5 + np.sin(np.arange(len(df_raw)) / 9)
        df = df_raw[["Delta_alpha", "Tau_fb", "Sigma_R", "Bz", "Dst"]]
    else:
        print("‚ö†Ô∏è Nenhum dado real encontrado ‚Äî gerando dados simulados")
        df = generate_realistic_data()

    forecaster = HACForecaster()
    for h in [1, 3, 6, 12]:
        result = forecaster.forecast(df, horizon=h)
        forecaster.plot_results(h)

    print("‚úÖ Execu√ß√£o conclu√≠da com sucesso!")


if __name__ == "__main__":
    main()
